{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_ULMFiT_model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO+tWUMKc3vqGNMLubGt5fq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WonJunPark/NLP_ULMFiT_model/blob/master/NLP_ULMFiT_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8A1535p67u9",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 업로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wykieCkj6_9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd # 데이터 전처리\n",
        "import numpy as np # 데이터 전처리\n",
        "import random #데이터 전처리\n",
        "from pandas import DataFrame #데이터 전처리\n",
        "from collections import Counter #데이터 전처리\n",
        "\n",
        "from tqdm import tqdm #시간 측정용\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer # model setting\n",
        "from sklearn.model_selection import train_test_split  # model setting\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB  # model 관련\n",
        "from sklearn.metrics import roc_auc_score  # model 성능 확인"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jeg8WFB7ABJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "dc8a0361-47bc-43a3-89f1-7a77febc416b"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMRKuQm-7AD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f255adaa-e5fe-4de1-e3f1-30dab2e1bcdd"
      },
      "source": [
        "!ls \"/content/gdrive/My Dr|ive/dacon"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `\"'\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s60Kj0Uz7FzB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "466accbb-0988-4f99-b067-b3c0e64a4084"
      },
      "source": [
        "cd /content/gdrive/My Drive/dacon"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/dacon\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq3_qTkV7F34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "ef60bf96-b979-46e0-e1b8-d20546c12407"
      },
      "source": [
        "train = pd.read_csv(\"train.csv\") #해당 14th data의 csv 파일 중 train.csv 불러오기\n",
        "train.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year_month</th>\n",
              "      <th>text</th>\n",
              "      <th>smishing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>XXX은행성산XXX팀장입니다.행복한주말되세요</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2017-01</td>\n",
              "      <td>1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id year_month                                               text  smishing\n",
              "0   0    2017-01                           XXX은행성산XXX팀장입니다.행복한주말되세요         0\n",
              "1   1    2017-01              오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림         0\n",
              "2   2    2017-01  안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...         0\n",
              "3   4    2017-01  XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...         0\n",
              "4   5    2017-01           1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuvDJIIK7F7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "42e3aa47-e75b-434c-9e2e-805b867eeaa0"
      },
      "source": [
        "test = pd.read_csv(\"public_test.csv\")\n",
        "test.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year_month</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>340000</td>\n",
              "      <td>2019-01</td>\n",
              "      <td>XXX고객님! 안녕하세요? 새롭게 시작하는 한 주 행복 가득하시길 기원합니다. 지난...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>340001</td>\n",
              "      <td>2019-01</td>\n",
              "      <td>긴급 안내  XXX은행 가락동 지점  - 헬리오XXX 기본XXX    대출이자를 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>340002</td>\n",
              "      <td>2019-01</td>\n",
              "      <td>XXX 고객님 안녕하세요올해는 미세먼지가 유난인거 같습니다.엊그제 새해가 시작된거같...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>340003</td>\n",
              "      <td>2019-01</td>\n",
              "      <td>XXX 고객님찾아온 행운을 잡으셨나요? 못잡으셨다면 이번에 다시 잡으시길 기원합니다...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>340004</td>\n",
              "      <td>2019-01</td>\n",
              "      <td>XXX 고객님새해 복 많이 받으세요 XXX은행 코스트코 퇴직연금 담당자입니다.  고...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id year_month                                               text\n",
              "0  340000    2019-01  XXX고객님! 안녕하세요? 새롭게 시작하는 한 주 행복 가득하시길 기원합니다. 지난...\n",
              "1  340001    2019-01   긴급 안내  XXX은행 가락동 지점  - 헬리오XXX 기본XXX    대출이자를 ...\n",
              "2  340002    2019-01  XXX 고객님 안녕하세요올해는 미세먼지가 유난인거 같습니다.엊그제 새해가 시작된거같...\n",
              "3  340003    2019-01  XXX 고객님찾아온 행운을 잡으셨나요? 못잡으셨다면 이번에 다시 잡으시길 기원합니다...\n",
              "4  340004    2019-01  XXX 고객님새해 복 많이 받으세요 XXX은행 코스트코 퇴직연금 담당자입니다.  고..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGxt6Diq7F1t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a374ba0e-79cd-4219-fe8c-09015141a5dc"
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((295945, 4), (1626, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-nCkxp77Oq5",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vbi5Q-H7QiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7293b627-2cda-4c81-961a-ca300797bce5"
      },
      "source": [
        "Counter(train['smishing'])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 277242, 1: 18703})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCVN349a7QnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(2019) #반복 수행시에도 동일한 결과 나올 수 있도록 시드 번호 지정\n",
        "train_nsm_list=list(train[train['smishing']!=1].index)\n",
        "train_nsmishing=random.sample(train_nsm_list, 11750 )\n",
        "\n",
        "random.seed(2019)\n",
        "train_sm_list=list(train[train['smishing']==1].index)\n",
        "train_smishing=random.sample(train_sm_list, 850 ) \n",
        "#0.066과 제일 비슷하게 나올 수 있도록  train data under sampling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q13b-oLD7RPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_xx=train.iloc[train_smishing+train_nsmishing,:].reset_index(drop=True) \n",
        "#under sampling으로 나온 index들로 train data 선별\n",
        "\n",
        "train_yy=DataFrame(train['smishing'],columns=['smishing']) \n",
        "train_yyy=train_yy.iloc[train_smishing+train_nsmishing,:].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTlrFMGl7RR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['smishing']=2 \n",
        "#train data와 동일한 형태 생성을 위해 임의의 숫자를 추가 \n",
        "#이후 스미싱 여부 확률 값으로 덮어 씌워짐\n",
        "test_xx=DataFrame(test['text'])\n",
        "test_yyy=DataFrame(test['smishing'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKqPRRy47Qlx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4b212b63-cfd0-409e-cd69-d7665be61278"
      },
      "source": [
        "train_xx.shape,train_yyy.shape,test_xx.shape,test_yyy.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12600, 4), (12600, 1), (1626, 1), (1626, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DzP_QEv7ZjK",
        "colab_type": "text"
      },
      "source": [
        "# 자연어 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGMSJni27cJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import konlpy\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "tokenizer = Mecab() # setting tokenizer using Mecab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rp9ufjo7cOy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1de671bb-9a19-4e0b-8885-1d31b6a3f88f"
      },
      "source": [
        "train_doc = [ ( tokenizer.pos(x), y ) for x, y in tqdm( zip( train_xx['text'], train_yyy['smishing'] ) )  ] # Mecab를 활용하여 text를 토큰화 시킴\n",
        "test_doc = [ ( tokenizer.pos(x), y ) for x, y in tqdm( zip( test_xx['text'], test_yyy['smishing'] ) )  ]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12600it [00:05, 2228.14it/s]\n",
            "1626it [00:01, 1426.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzR_a6zj7cUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = ['하','시','XXX', '%','.','주','에','의', '을', '를', '이', '가',\n",
        "              '1','2','3','4','5','6','7','8','9','0','습니다','로','있','고',\n",
        "              '만','되','면','인','한','원','겠','들','해','어','및','수','게',\n",
        "              '내','지','대','도','중','과','입니다','신','기','실','건','균',\n",
        "              '보','연','님','세','보내','할','적','저','받','여','알','아', \n",
        "              '은', '는', '사','나', '와','분','으로','헙니다', '않','-', \n",
        "              '년','권','에서','(', ')', ':', '!', '?', ')-', '.-', \n",
        "              'ㅡ', 'XXXXXX', '..','.(' ] #필요없는 단어 리스트\n",
        "\n",
        "def get_couple(_words): #필요없는 단어들 없애는 함수\n",
        "    global stopwords\n",
        "    _words = [x for x in _words if x[0] not in stopwords]\n",
        "    l = len(_words)\n",
        "    for i in range(l-1):\n",
        "        yield _words[i][0], _words[i+1][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AhHiew77cR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, Y_train = [], []\n",
        "for lwords in train_doc:\n",
        "    Y_train.append(lwords[1])\n",
        "    \n",
        "    temp = []\n",
        "    for x, y in get_couple(lwords[0]):\n",
        "        temp.append(\"{}.{}\".format(x, y))\n",
        "    \n",
        "    X_train.append(\" \".join(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpQ6tpws7cM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = []\n",
        "for lwords in test_doc:\n",
        "    \n",
        "    temp = []\n",
        "    for x, y in get_couple(lwords[0]):\n",
        "        temp.append(\"{}.{}\".format(x, y))\n",
        "    \n",
        "    X_test.append(\" \".join(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rxAfa7U7loX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v=CountVectorizer()\n",
        "\n",
        "v.fit(X_train)\n",
        "\n",
        "vec_x_train= v.transform(X_train).toarray()\n",
        "vec_x_test= v.transform(X_test).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAt29Lx9735l",
        "colab_type": "text"
      },
      "source": [
        "# Model build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qPzyT9n77BM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trl = vec_x_train[3780:]\n",
        "vec_x_val = vec_x_train[:3780]\n",
        "Y_train2 = Y_train[3780:]\n",
        "Y_val = Y_train[:3780]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvmqmqpA7lts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vec_x_train2 = vec_x_train[3780:]\n",
        "vec_x_val = vec_x_train[:3780]\n",
        "Y_train2 = Y_train[3780:]\n",
        "Y_val = Y_train[:3780]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3o2urFU7lrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn4Vd-7d7lmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcqdPW7dhn2p",
        "colab_type": "text"
      },
      "source": [
        "# NLP ULMFiT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC9uIgTLhBlJ",
        "colab_type": "code",
        "outputId": "392b1130-7c9b-414f-86c7-1621317cca91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "source": [
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
        "!pip install fastai"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Requirement already satisfied: torch_nightly in /usr/local/lib/python3.6/dist-packages (1.2.0.dev20190805+cu92)\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.60)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.4.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (20.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.17.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (6.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.25.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.21.0)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.2.2)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.1)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->fastai) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2019.11.28)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.0.1)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.1)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (7.0.8)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.6.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.0.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (42.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy>=2.0.18->fastai) (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDOEBTIQhYCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.text import * \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import io\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrszkQsHhdEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHDcy9_hhdI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'label':dataset.target, 'text':dataset.data})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va5cXu-rhdGn",
        "colab_type": "code",
        "outputId": "a969bd6e-2466-457a-b95b-db6f95e14a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgSailMmhip2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[df['label'].isin([1,10])]\n",
        "df = df.reset_index(drop = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65feBhFWhixF",
        "colab_type": "code",
        "outputId": "4be9f6a0-8511-4681-ba13-61790faf9ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10    600\n",
              "1     584\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ponA11NRh4FW",
        "colab_type": "text"
      },
      "source": [
        "data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v24XyhjLhiz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRXTpjc2hi2i",
        "colab_type": "code",
        "outputId": "eb4abb5c-7bf6-4fb2-ece1-98a2efaa84e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrQx7noVhiv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenization \n",
        "tokenized_doc = df['text'].apply(lambda x: x.split())\n",
        "\n",
        "# remove stop-words \n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
        "\n",
        "# de-tokenization \n",
        "detokenized_doc = [] \n",
        "for i in range(len(df)): \n",
        "    t = ' '.join(tokenized_doc[i]) \n",
        "    detokenized_doc.append(t) \n",
        "\n",
        "df['text'] = detokenized_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7PEyAoyhity",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into training and validation set\n",
        "df_trn, df_val = train_test_split(df, stratify = df['label'], test_size = 0.4, random_state = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-dHQ1AMh_ei",
        "colab_type": "code",
        "outputId": "59a73f9c-ef0a-4c05-eba5-12cc2dbcd487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "df_trn.shape, df_val.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((710, 2), (474, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GKoPul2h_1b",
        "colab_type": "code",
        "outputId": "78e6d96e-f5a7-4b93-b475-c039f5fad1f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# Language model data\n",
        "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")\n",
        "\n",
        "# Classifier model data\n",
        "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMzo7a2Bh_yf",
        "colab_type": "code",
        "outputId": "1dd6e4d3-658e-4bd1-c421-2683fa332408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtBE3iWlh_v_",
        "colab_type": "code",
        "outputId": "133b04ee-8bc4-4db6-b7a0-da52b7f49b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        }
      },
      "source": [
        "# train the learner object with learning rate = 1e-2\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.114468</td>\n",
              "      <td>5.208203</td>\n",
              "      <td>0.244324</td>\n",
              "      <td>04:15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtK_qPDfixTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save_encoder('ft_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYC9VO_mixo-",
        "colab_type": "code",
        "outputId": "b1d4e35e-75b3-439c-877d-4a0d1dc8b8e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.7)\n",
        "learn.load_encoder('ft_enc')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (710 items)\n",
              "x: TextList\n",
              "xxbos xxmaj it looks like xxmaj edmonton xxmaj oilers decided take xxmaj european xxunk spring xxmaj ranford xxmaj tugnutt xxmaj benning xxmaj manson xxmaj smith xxmaj buchberger xxmaj corson playing xxmaj canada xxmaj podein xxmaj weight playing xxup us xxmaj is xxmaj kravchuk playing xxmaj xxunk i know nagging injuries late season xxmaj podein interesting case eligible play xxmaj cape xxmaj breton xxup ahl playoffs like xxmaj kovalev xxmaj zubov xxmaj andersson obviously xxmaj sather xxmaj pocklington total xxunk everyone makes certainly case massively xxunk xxmaj paramount xxmaj new xxmaj york xxmaj rangers,xxbos xxmaj this xxunk xxmaj speaking die hard i i read xxunk hard xxunk xxmaj toronto xxmaj cup finals xxmaj first anyone planet heard team xxmaj detroit xxmaj al xxmaj xxunk however spell idiot name must xxmaj chicago xxup espn said even close xxmaj chicago xxunk win xxmaj norris xxmaj division xxmaj playoffs team close xxmaj everyone picking xxmaj chicago i get says easy choice xxmaj god xxmaj chicago xxmaj wings division point two followed closely xxmaj toronto also good team xxmaj as xxmaj leafs beating xxmaj detroit doubt even going get xxmaj chicago xxmaj if even xxunk get past xxmaj hawks would probably face xxmaj vancouver lose xxmaj as xxmaj the xxmaj habs reaching xxmaj finals forget xxmaj even i devoted xxmaj wings fan watch xxmaj penguins easily three xxunk xxmaj cup winners xxmaj lemieux xxmaj jagr xxmaj tocchet xxmaj stevens xxmaj barrasso done deal xxmaj sorry xxmaj detroit wait xxunk next year xxmaj but hey xxmaj paul picks everyone right xxunk xxmaj leafs xxmaj finals xxmaj yeah xxmaj if make i walk xxmaj toronto get tickets mile walk xxmaj ryan,xxbos xxmaj the idea clip one polygon using another polygon necessarily rectangular window xxmaj my problem finding new vertices resulting xxunk first one xxmaj is simply matter extending usual algorithm whereby edges one polygon checked another polygon xxmaj is simpler way xxmaj comments welcome,xxbos i xxmaj edmonton usually least xxup often case xxunk actual xxup abc xxunk xxmaj kings xxmaj flames game i whoever said earlier xxmaj don xxmaj xxunk er xxmaj whitman poor commentator hockey xxmaj normally xxmaj oilers still playing xxunk i would turn sound listen radio broadcast get decent play play announcing,xxbos xxmaj you know absolutely right i think round players xxmaj european xxunk ship em back came xxmaj let see start i dunno xxmaj lemieux xxmaj hmmm sounds like xxmaj french blood xxmaj hey xxmaj france part xxmaj europe xxmaj send xxmaj xxunk xxunk boy back xxmaj sheesh i think would hard find xxmaj native xxmaj americans xxmaj native xxmaj canadians matter would xxunk claim great continent xxmaj ya see believe xxunk xxunk sort xxmaj if really think xxmaj mogilny xxmaj bure xxmaj selanne et al improved xxup nhl i sure understand game\n",
              "y: CategoryList\n",
              "10,10,1,10,10\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (474 items)\n",
              "x: TextList\n",
              "xxbos i looking source code radiosity method i know kind machine want program xxmaj radiance comes c source code i ftp access i tell get via way,xxbos i interested information xxunk imaging sun workstation xxmaj for part i need know hardware available interface system whether xxunk rates sufficient produce quality image xxunk xxmaj any information subject would greatly appreciated,xxbos xxmaj does anyone xxup nhl xxup standings xxmaj march th i need xxup xxunk project xxmaj please post email xxup thanks,xxbos a little xxunk xxmaj basic xxmaj mike info xxmaj for xxmaj xxunk xxunk xxup abc announcing xxunk xxmaj devils xxmaj isles xxmaj pittsburgh xxmaj gary xxmaj thorne play play xxmaj bill xxmaj clement color xxmaj al xxmaj xxunk xxunk xxunk outside xxunk xxunk xxmaj this xxunk primarily seen xxmaj east xxmaj coast xxmaj st xxmaj louis xxmaj chicago xxmaj mike xxmaj xxunk play play xxmaj jim xxmaj xxunk color xxmaj tom xxmaj xxunk xxunk xxunk xxmaj this xxunk primarily seen xxmaj midwest parts xxmaj south xxup la xxmaj calgary xxmaj al xxmaj do xxmaj you xxmaj believe xxmaj xxunk xxmaj michaels play play xxmaj john xxmaj davidson color xxmaj mark xxmaj jones xxunk reporter xxmaj this xxunk seen xxmaj western xxup usa xxmaj montreal xxunk xxmaj xxunk xxmaj xxunk xxunk studio xxup abc xxmaj up xxmaj close xxmaj personal xxmaj mario xxmaj saturday xxmaj wide xxmaj world xxmaj sports xxup edt xxmaj sunday first xxup nhl playoff regular network xxunk years counting silly xxmaj all xxmaj star games xxup xxunk last years xxmaj for xxmaj sunday games xxup abc use xxunk behind goal super super xxunk xxunk close xxunk player faces face xxunk xxup espn xxup abc able use new favorite xxunk ice level shot xxmaj pittsburgh many seats would removed xxunk xxmaj in case blowout xxunk xxmaj pittsburgh xxup abc switch xxmaj chicago game come back xxmaj pittsburgh game updates game gets closer xxmaj xxunk xxup abc xxunk huge ratings hockey standards since xxmaj top xxup us xxup tv markets involved xxup ny xxunk area xxup ny xxmaj islanders xxup nj xxmaj devils xxmaj chicago blackhawks xxup la xxmaj kings xxmaj stay tuned xxmaj thanks xxmaj mike,xxbos xxmaj world xxmaj championships xxmaj germany xxmaj group a results xxup sweden xxup canada st nd xxup can xxmaj geoff xxmaj sanderson xxmaj kevin xxmaj dineen xxup xxunk xxmaj patrik xxmaj xxunk xxmaj jan xxmaj xxunk pp rd xxup can xxmaj geoff xxmaj sanderson ps xxup can xxmaj mike xxmaj gartner xxmaj greg xxmaj xxunk xxmaj adam xxmaj graves xxup can xxmaj rod xxmaj brind xxmaj amour xxmaj shayne xxmaj corson xxmaj shots goal xxmaj penalties xxmaj attendance xxmaj referee xxmaj sweden min xxmaj rob xxmaj xxunk xxup usa xxmaj canada min xxmaj bill xxmaj ranford stopped shots lead xxmaj canada victory well played game xxmaj the first period started give away xxmaj canadian defenseman xxmaj xxunk came alone xxmaj ranford put puck xxunk xxmaj ranford xxmaj later xxmaj kevin xxmaj dineen great opportunity xxmaj soderstrom played well xxmaj xxunk xxmaj nilsson couple great xxunk set xxmaj jan xxmaj xxunk xxmaj ranford came big xxmaj period ended xxunk edge xxmaj sweden creating opportunities xxmaj second period action saw xxmaj tommy xxmaj soderstrom making xxup great save xxmaj mark xxmaj recchi made xxunk cross ice pass xxmaj lindros xxmaj eric one xxunk puck xxmaj soderstrom make glove hand save xxmaj at minute mark xxmaj canada started applying pressure xxmaj xxunk xxmaj sanderson xxmaj dineen xxmaj brind xxmaj amour worked hard kept puck xxmaj xxunk zone xxmaj dineen gave puck xxmaj sanderson skated around xxunk xxmaj swedish defenseman came xxmaj soderstrom made wrist shot went xxmaj soderstrom far post xxmaj canada xxmaj the xxmaj xxunk picked game xxmaj peter xxmaj xxunk shot hit xxmaj ranford post inside went parallel goal line xxmaj then xxmaj gartner got penalty xxmaj xxunk power play xxmaj jan xxmaj xxunk took shot slot xxmaj ranford gave rebound xxmaj xxunk saw xxmaj xxunk far post passed puck xxmaj ranford beat xxmaj third period started periods xxmaj xxunk pressure xxmaj canadians always xxunk close xxmaj xxunk goal xxmaj at xxmaj canada created great chances xxmaj xxunk xxmaj xxunk forced cover puck xxmaj xxunk goal crease since xxmaj soderstrom lost sight xxmaj that xxunk penalty shot since defenseman cover puck goal crease xxmaj geoff xxmaj sanderson took penalty shot first ever explained xxunk put low xxmaj soderstrom stick side close post xxmaj excellent penalty shot give xxmaj canada go ahead goal xxmaj canada increased lead suspect xxunk xxmaj gartner xxunk bouncing puck past xxmaj soderstrom make xxmaj the xxmaj xxunk xxunk gas produce good scoring chances periods xxmaj the goal came second left xxmaj rod xxmaj brind xxmaj amour scoring rebound xxmaj soderstrom xxmaj swedish defense already xxunk xxunk room a good game best xxup wc far goalies playing great xxmaj soderstrom best player xxmaj sweden xxmaj ranford even played better xxmaj soderstrom tells something xxmaj ranford xxmaj probably best goalie world comments game xxmaj canada played disciplined defense xxmaj ranford pointed easy play well good defense xxmaj lindros played a xxup lot played well xxmaj sanderson xxunk game xxunk two goals xxmaj the xxmaj xxunk xxmaj naslund xxmaj xxunk line xxmaj sweden best along xxmaj xxunk xxmaj xxunk xxmaj nilsson xxmaj swedish defense played well xxunk xxunk xxmaj peter xxmaj xxunk task xxunk xxunk xxunk xxmaj eric xxmaj lindros managed well xxmaj ranger defenseman xxmaj peter xxmaj andersson finally got go xxup wc considering xxunk xxmaj germany hours game played well xxmaj swedish coach xxmaj xxunk xxmaj xxunk xxunk game xxunk xxmaj xxunk xxunk score xxunk linesman mistake goal xxmaj lines information follows xxup italy xxup switzerland st nd xxup xxunk xxmaj xxunk rd xxmaj penalties xxup xxunk min xxup xxunk min xxmaj referee xxmaj xxunk xxmaj xxunk xxmaj slovakia xxmaj attendance xxmaj group b results xxup czech xxup republic xxup germany st nd xxup xxunk xxmaj xxunk xxmaj xxunk xxup xxunk xxmaj jiri xxmaj xxunk xxup xxunk xxmaj petr xxmaj xxunk rd xxup xxunk xxmaj xxunk xxmaj xxunk xxup xxunk xxmaj josef xxmaj beranek xxmaj penalties xxup xxunk min xxup xxunk min min min game penalty xxmaj referee xxmaj xxunk xxmaj xxunk xxmaj canada xxmaj attendance xxmaj the xxmaj xxunk clearly better xxmaj xxunk xxmaj german crowd showed xxunk throwing stuff ice xxup finland xxup usa st nd xxup xxunk xxmaj xxunk xxmaj xxunk rd xxup usa xxmaj ed xxmaj olczyk xxmaj penalties xxup xxunk min xxup usa min xxmaj referee xxmaj xxunk xxmaj xxunk xxmaj russia xxmaj attendance i hope xxmaj xxunk provide information game i see whole game xxmaj the xxmaj xxunk took lead xxmaj xxunk xxmaj xxunk slap shot blue line soft goal xxunk xxmaj mike xxmaj richter xxmaj as far play second period goes xxmaj xxunk seemed control lead warranted i saw xxup sweden xxup canada xxmaj goaltender xxmaj tommy xxmaj soderstrom xxmaj bill xxmaj ranford xxmaj defense xxmaj kenneth xxmaj xxunk xxmaj norm xxmaj maciver xxmaj fredrik xxmaj stillman xxmaj dave xxmaj manson xxmaj peter xxmaj xxunk xxmaj geoff xxmaj smith xxmaj peter xxmaj andersson xxmaj brian xxmaj benning xxmaj xxunk xxmaj xxunk xxmaj terry xxmaj carkner xxmaj roger xxmaj xxunk xxmaj garry xxmaj galley xxmaj derek xxmaj xxunk xxmaj forwards xxmaj mikael xxmaj xxunk xxmaj dave xxmaj gagner xxmaj thomas xxmaj xxunk xxmaj adam xxmaj graves xxmaj mikael xxmaj andersson xxmaj mike xxmaj gartner xxmaj markus xxmaj naslund xxmaj paul xxmaj kariya xxmaj peter xxmaj xxunk xxmaj eric xxmaj lindros xxmaj jonas xxmaj xxunk xxmaj mark xxmaj recchi xxmaj patrik xxmaj xxunk xxmaj rod xxmaj brind xxmaj amour xxmaj jan xxmaj xxunk xxmaj shayne xxmaj corson xxmaj xxunk xxmaj nilsson xxmaj kevin xxmaj dineen xxmaj xxunk xxmaj xxunk xxmaj geoff xxmaj sanderson xxmaj michael xxmaj nylander xxmaj greg xxmaj xxunk xxmaj andersson xxmaj xxunk xxmaj brian xxmaj savage xxmaj kelly xxmaj buchberger\n",
              "y: CategoryList\n",
              "1,1,10,10,10\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(6600, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(6600, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa71e573620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (710 items)\n",
              "x: TextList\n",
              "xxbos xxmaj it looks like xxmaj edmonton xxmaj oilers decided take xxmaj european xxunk spring xxmaj ranford xxmaj tugnutt xxmaj benning xxmaj manson xxmaj smith xxmaj buchberger xxmaj corson playing xxmaj canada xxmaj podein xxmaj weight playing xxup us xxmaj is xxmaj kravchuk playing xxmaj xxunk i know nagging injuries late season xxmaj podein interesting case eligible play xxmaj cape xxmaj breton xxup ahl playoffs like xxmaj kovalev xxmaj zubov xxmaj andersson obviously xxmaj sather xxmaj pocklington total xxunk everyone makes certainly case massively xxunk xxmaj paramount xxmaj new xxmaj york xxmaj rangers,xxbos xxmaj this xxunk xxmaj speaking die hard i i read xxunk hard xxunk xxmaj toronto xxmaj cup finals xxmaj first anyone planet heard team xxmaj detroit xxmaj al xxmaj xxunk however spell idiot name must xxmaj chicago xxup espn said even close xxmaj chicago xxunk win xxmaj norris xxmaj division xxmaj playoffs team close xxmaj everyone picking xxmaj chicago i get says easy choice xxmaj god xxmaj chicago xxmaj wings division point two followed closely xxmaj toronto also good team xxmaj as xxmaj leafs beating xxmaj detroit doubt even going get xxmaj chicago xxmaj if even xxunk get past xxmaj hawks would probably face xxmaj vancouver lose xxmaj as xxmaj the xxmaj habs reaching xxmaj finals forget xxmaj even i devoted xxmaj wings fan watch xxmaj penguins easily three xxunk xxmaj cup winners xxmaj lemieux xxmaj jagr xxmaj tocchet xxmaj stevens xxmaj barrasso done deal xxmaj sorry xxmaj detroit wait xxunk next year xxmaj but hey xxmaj paul picks everyone right xxunk xxmaj leafs xxmaj finals xxmaj yeah xxmaj if make i walk xxmaj toronto get tickets mile walk xxmaj ryan,xxbos xxmaj the idea clip one polygon using another polygon necessarily rectangular window xxmaj my problem finding new vertices resulting xxunk first one xxmaj is simply matter extending usual algorithm whereby edges one polygon checked another polygon xxmaj is simpler way xxmaj comments welcome,xxbos i xxmaj edmonton usually least xxup often case xxunk actual xxup abc xxunk xxmaj kings xxmaj flames game i whoever said earlier xxmaj don xxmaj xxunk er xxmaj whitman poor commentator hockey xxmaj normally xxmaj oilers still playing xxunk i would turn sound listen radio broadcast get decent play play announcing,xxbos xxmaj you know absolutely right i think round players xxmaj european xxunk ship em back came xxmaj let see start i dunno xxmaj lemieux xxmaj hmmm sounds like xxmaj french blood xxmaj hey xxmaj france part xxmaj europe xxmaj send xxmaj xxunk xxunk boy back xxmaj sheesh i think would hard find xxmaj native xxmaj americans xxmaj native xxmaj canadians matter would xxunk claim great continent xxmaj ya see believe xxunk xxunk sort xxmaj if really think xxmaj mogilny xxmaj bure xxmaj selanne et al improved xxup nhl i sure understand game\n",
              "y: CategoryList\n",
              "10,10,1,10,10\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (474 items)\n",
              "x: TextList\n",
              "xxbos i looking source code radiosity method i know kind machine want program xxmaj radiance comes c source code i ftp access i tell get via way,xxbos i interested information xxunk imaging sun workstation xxmaj for part i need know hardware available interface system whether xxunk rates sufficient produce quality image xxunk xxmaj any information subject would greatly appreciated,xxbos xxmaj does anyone xxup nhl xxup standings xxmaj march th i need xxup xxunk project xxmaj please post email xxup thanks,xxbos a little xxunk xxmaj basic xxmaj mike info xxmaj for xxmaj xxunk xxunk xxup abc announcing xxunk xxmaj devils xxmaj isles xxmaj pittsburgh xxmaj gary xxmaj thorne play play xxmaj bill xxmaj clement color xxmaj al xxmaj xxunk xxunk xxunk outside xxunk xxunk xxmaj this xxunk primarily seen xxmaj east xxmaj coast xxmaj st xxmaj louis xxmaj chicago xxmaj mike xxmaj xxunk play play xxmaj jim xxmaj xxunk color xxmaj tom xxmaj xxunk xxunk xxunk xxmaj this xxunk primarily seen xxmaj midwest parts xxmaj south xxup la xxmaj calgary xxmaj al xxmaj do xxmaj you xxmaj believe xxmaj xxunk xxmaj michaels play play xxmaj john xxmaj davidson color xxmaj mark xxmaj jones xxunk reporter xxmaj this xxunk seen xxmaj western xxup usa xxmaj montreal xxunk xxmaj xxunk xxmaj xxunk xxunk studio xxup abc xxmaj up xxmaj close xxmaj personal xxmaj mario xxmaj saturday xxmaj wide xxmaj world xxmaj sports xxup edt xxmaj sunday first xxup nhl playoff regular network xxunk years counting silly xxmaj all xxmaj star games xxup xxunk last years xxmaj for xxmaj sunday games xxup abc use xxunk behind goal super super xxunk xxunk close xxunk player faces face xxunk xxup espn xxup abc able use new favorite xxunk ice level shot xxmaj pittsburgh many seats would removed xxunk xxmaj in case blowout xxunk xxmaj pittsburgh xxup abc switch xxmaj chicago game come back xxmaj pittsburgh game updates game gets closer xxmaj xxunk xxup abc xxunk huge ratings hockey standards since xxmaj top xxup us xxup tv markets involved xxup ny xxunk area xxup ny xxmaj islanders xxup nj xxmaj devils xxmaj chicago blackhawks xxup la xxmaj kings xxmaj stay tuned xxmaj thanks xxmaj mike,xxbos xxmaj world xxmaj championships xxmaj germany xxmaj group a results xxup sweden xxup canada st nd xxup can xxmaj geoff xxmaj sanderson xxmaj kevin xxmaj dineen xxup xxunk xxmaj patrik xxmaj xxunk xxmaj jan xxmaj xxunk pp rd xxup can xxmaj geoff xxmaj sanderson ps xxup can xxmaj mike xxmaj gartner xxmaj greg xxmaj xxunk xxmaj adam xxmaj graves xxup can xxmaj rod xxmaj brind xxmaj amour xxmaj shayne xxmaj corson xxmaj shots goal xxmaj penalties xxmaj attendance xxmaj referee xxmaj sweden min xxmaj rob xxmaj xxunk xxup usa xxmaj canada min xxmaj bill xxmaj ranford stopped shots lead xxmaj canada victory well played game xxmaj the first period started give away xxmaj canadian defenseman xxmaj xxunk came alone xxmaj ranford put puck xxunk xxmaj ranford xxmaj later xxmaj kevin xxmaj dineen great opportunity xxmaj soderstrom played well xxmaj xxunk xxmaj nilsson couple great xxunk set xxmaj jan xxmaj xxunk xxmaj ranford came big xxmaj period ended xxunk edge xxmaj sweden creating opportunities xxmaj second period action saw xxmaj tommy xxmaj soderstrom making xxup great save xxmaj mark xxmaj recchi made xxunk cross ice pass xxmaj lindros xxmaj eric one xxunk puck xxmaj soderstrom make glove hand save xxmaj at minute mark xxmaj canada started applying pressure xxmaj xxunk xxmaj sanderson xxmaj dineen xxmaj brind xxmaj amour worked hard kept puck xxmaj xxunk zone xxmaj dineen gave puck xxmaj sanderson skated around xxunk xxmaj swedish defenseman came xxmaj soderstrom made wrist shot went xxmaj soderstrom far post xxmaj canada xxmaj the xxmaj xxunk picked game xxmaj peter xxmaj xxunk shot hit xxmaj ranford post inside went parallel goal line xxmaj then xxmaj gartner got penalty xxmaj xxunk power play xxmaj jan xxmaj xxunk took shot slot xxmaj ranford gave rebound xxmaj xxunk saw xxmaj xxunk far post passed puck xxmaj ranford beat xxmaj third period started periods xxmaj xxunk pressure xxmaj canadians always xxunk close xxmaj xxunk goal xxmaj at xxmaj canada created great chances xxmaj xxunk xxmaj xxunk forced cover puck xxmaj xxunk goal crease since xxmaj soderstrom lost sight xxmaj that xxunk penalty shot since defenseman cover puck goal crease xxmaj geoff xxmaj sanderson took penalty shot first ever explained xxunk put low xxmaj soderstrom stick side close post xxmaj excellent penalty shot give xxmaj canada go ahead goal xxmaj canada increased lead suspect xxunk xxmaj gartner xxunk bouncing puck past xxmaj soderstrom make xxmaj the xxmaj xxunk xxunk gas produce good scoring chances periods xxmaj the goal came second left xxmaj rod xxmaj brind xxmaj amour scoring rebound xxmaj soderstrom xxmaj swedish defense already xxunk xxunk room a good game best xxup wc far goalies playing great xxmaj soderstrom best player xxmaj sweden xxmaj ranford even played better xxmaj soderstrom tells something xxmaj ranford xxmaj probably best goalie world comments game xxmaj canada played disciplined defense xxmaj ranford pointed easy play well good defense xxmaj lindros played a xxup lot played well xxmaj sanderson xxunk game xxunk two goals xxmaj the xxmaj xxunk xxmaj naslund xxmaj xxunk line xxmaj sweden best along xxmaj xxunk xxmaj xxunk xxmaj nilsson xxmaj swedish defense played well xxunk xxunk xxmaj peter xxmaj xxunk task xxunk xxunk xxunk xxmaj eric xxmaj lindros managed well xxmaj ranger defenseman xxmaj peter xxmaj andersson finally got go xxup wc considering xxunk xxmaj germany hours game played well xxmaj swedish coach xxmaj xxunk xxmaj xxunk xxunk game xxunk xxmaj xxunk xxunk score xxunk linesman mistake goal xxmaj lines information follows xxup italy xxup switzerland st nd xxup xxunk xxmaj xxunk rd xxmaj penalties xxup xxunk min xxup xxunk min xxmaj referee xxmaj xxunk xxmaj xxunk xxmaj slovakia xxmaj attendance xxmaj group b results xxup czech xxup republic xxup germany st nd xxup xxunk xxmaj xxunk xxmaj xxunk xxup xxunk xxmaj jiri xxmaj xxunk xxup xxunk xxmaj petr xxmaj xxunk rd xxup xxunk xxmaj xxunk xxmaj xxunk xxup xxunk xxmaj josef xxmaj beranek xxmaj penalties xxup xxunk min xxup xxunk min min min game penalty xxmaj referee xxmaj xxunk xxmaj xxunk xxmaj canada xxmaj attendance xxmaj the xxmaj xxunk clearly better xxmaj xxunk xxmaj german crowd showed xxunk throwing stuff ice xxup finland xxup usa st nd xxup xxunk xxmaj xxunk xxmaj xxunk rd xxup usa xxmaj ed xxmaj olczyk xxmaj penalties xxup xxunk min xxup usa min xxmaj referee xxmaj xxunk xxmaj xxunk xxmaj russia xxmaj attendance i hope xxmaj xxunk provide information game i see whole game xxmaj the xxmaj xxunk took lead xxmaj xxunk xxmaj xxunk slap shot blue line soft goal xxunk xxmaj mike xxmaj richter xxmaj as far play second period goes xxmaj xxunk seemed control lead warranted i saw xxup sweden xxup canada xxmaj goaltender xxmaj tommy xxmaj soderstrom xxmaj bill xxmaj ranford xxmaj defense xxmaj kenneth xxmaj xxunk xxmaj norm xxmaj maciver xxmaj fredrik xxmaj stillman xxmaj dave xxmaj manson xxmaj peter xxmaj xxunk xxmaj geoff xxmaj smith xxmaj peter xxmaj andersson xxmaj brian xxmaj benning xxmaj xxunk xxmaj xxunk xxmaj terry xxmaj carkner xxmaj roger xxmaj xxunk xxmaj garry xxmaj galley xxmaj derek xxmaj xxunk xxmaj forwards xxmaj mikael xxmaj xxunk xxmaj dave xxmaj gagner xxmaj thomas xxmaj xxunk xxmaj adam xxmaj graves xxmaj mikael xxmaj andersson xxmaj mike xxmaj gartner xxmaj markus xxmaj naslund xxmaj paul xxmaj kariya xxmaj peter xxmaj xxunk xxmaj eric xxmaj lindros xxmaj jonas xxmaj xxunk xxmaj mark xxmaj recchi xxmaj patrik xxmaj xxunk xxmaj rod xxmaj brind xxmaj amour xxmaj jan xxmaj xxunk xxmaj shayne xxmaj corson xxmaj xxunk xxmaj nilsson xxmaj kevin xxmaj dineen xxmaj xxunk xxmaj xxunk xxmaj geoff xxmaj sanderson xxmaj michael xxmaj nylander xxmaj greg xxmaj xxunk xxmaj andersson xxmaj xxunk xxmaj brian xxmaj savage xxmaj kelly xxmaj buchberger\n",
              "y: CategoryList\n",
              "1,1,10,10,10\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(6600, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(6600, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa71e573620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(6600, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(6600, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(6600, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(6600, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtJIDoyeixth",
        "colab_type": "code",
        "outputId": "3414add7-e5c0-45f3-f22f-364a73319f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        }
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.356876</td>\n",
              "      <td>0.152218</td>\n",
              "      <td>0.953587</td>\n",
              "      <td>10:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXKRID_gixr0",
        "colab_type": "code",
        "outputId": "0442f205-66e0-492e-e307-d56cec0d4cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# get predictions\n",
        "preds, targets = learn.get_preds()\n",
        "\n",
        "predictions = np.argmax(preds, axis = 1)\n",
        "pd.crosstab(predictions, targets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>217</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17</td>\n",
              "      <td>235</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    0    1\n",
              "row_0          \n",
              "0      217    5\n",
              "1       17  235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tIuXY76o1NH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKQ-76zA6u4p",
        "colab_type": "text"
      },
      "source": [
        "# Mecab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpbamVne6yBU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "176737cc-27c7-43b1-e488-488f692e8fdd"
      },
      "source": [
        "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 47 (delta 16), reused 20 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (47/47), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaGNlOCR6yGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "85a69dbf-1ff0-4b29-8596-550d6efd7b75"
      },
      "source": [
        "ls"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mMecab-ko-for-Google-Colab\u001b[0m/  \u001b[01;34mmodels\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Joe-jw6yJK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "49486523-df1b-40c0-d840-a9caf0f7c6c7"
      },
      "source": [
        "cd Mecab-ko-for-Google-Colab/"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3JXcxII6yEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0d16a603-ff4f-420a-d969-352ae6b8acbe"
      },
      "source": [
        "ls"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mimages\u001b[0m/  install_mecab-ko_on_colab190912.sh  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVaa90C-62MJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01fb82d9-002d-43c3-b851-4db0d9f62732"
      },
      "source": [
        "! bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 236kB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/62/0f312d578e0165e9b5e8fcae0291f7ee83783b3805f59071006b21229d55/JPype1-0.7.1.tar.gz (481kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.5)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Building wheels for collected packages: JPype1\n",
            "  Building wheel for JPype1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for JPype1: filename=JPype1-0.7.1-cp36-cp36m-linux_x86_64.whl size=2448199 sha256=c88ff8d6070c13bec961ce73265dd47775bbc6e574716ed1417e824ebaf64d81\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/49/6a/4393ef8542c00becf80691bd242693db9e263d6e499323a984\n",
            "Successfully built JPype1\n",
            "Installing collected packages: JPype1, beautifulsoup4, colorama, tweepy, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-0.7.1 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.8.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2020-01-09 20:08:24--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.2, 18.205.93.0, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=ipW0%2BemRhFh2m4r6OKpnKbEpLys%3D&Expires=1578601431&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22 [following]\n",
            "--2020-01-09 20:08:24--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=ipW0%2BemRhFh2m4r6OKpnKbEpLys%3D&Expires=1578601431&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.42.76\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.42.76|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  3.49MB/s    in 0.4s    \n",
            "\n",
            "2020-01-09 20:08:25 (3.49 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2020-01-09 20:10:00--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.2, 18.205.93.0, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=DiJxwrmSPIR6Q2oWfUC6iIKnin8%3D&Expires=1578602400&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22 [following]\n",
            "--2020-01-09 20:10:00--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=DiJxwrmSPIR6Q2oWfUC6iIKnin8%3D&Expires=1578602400&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.128.227\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.128.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  26.3MB/s    in 1.8s    \n",
            "\n",
            "2020-01-09 20:10:03 (26.3 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdJYeS_962-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}